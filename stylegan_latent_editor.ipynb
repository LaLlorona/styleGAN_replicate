{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "stylegan_latent_editor",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GnjO12rwOrH",
        "outputId": "eac53630-c86f-4d35-c290-ad6ecc911dae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "/content/gdrive/My Drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd /content/gdrive/My\\ Drive/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd study/deep/styleGAN"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_kuHDVPwet9",
        "outputId": "1b8f8ab2-e3b3-4be3-b3f1-48e641d05ff3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/My Drive/study/deep/styleGAN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/pacifinapacific/StyleGAN_LatentEditor.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijR5rcMKw53t",
        "outputId": "69a455b9-c579-466a-e20b-ade228f81c41"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'StyleGAN_LatentEditor' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd StyleGAN_LatentEditor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DDYHxkvw-TU",
        "outputId": "cd0b9b25-5bb3-4b84-fe00-23ca7f2af016"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/study/deep/styleGAN/StyleGAN_LatentEditor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==1.15.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGDVxKSszN9O",
        "outputId": "6130707b-07a9-467f-cca0-9e27f1774b93"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==1.15.2\n",
            "  Downloading tensorflow-1.15.2-cp37-cp37m-manylinux2010_x86_64.whl (110.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 110.5 MB 36 kB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.0.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.21.6)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (3.17.3)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.46.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (0.2.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (0.8.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (3.3.0)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 54.5 MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator==1.15.1\n",
            "  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
            "\u001b[K     |████████████████████████████████| 503 kB 64.7 MB/s \n",
            "\u001b[?25hCollecting keras-applications>=1.0.8\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 8.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (0.37.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.1.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.14.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.15.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.2) (3.1.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (3.3.7)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (57.4.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (4.11.4)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (4.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (3.8.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow==1.15.2) (1.5.2)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7554 sha256=2990e92fe716ba90acde8cde01d68bdbb277a2a1620aa0f1f94a91e741829822\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
            "Successfully built gast\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras-applications, gast, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.8.0\n",
            "    Uninstalling tensorboard-2.8.0:\n",
            "      Successfully uninstalled tensorboard-2.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.2+zzzcolab20220527125636\n",
            "    Uninstalling tensorflow-2.8.2+zzzcolab20220527125636:\n",
            "      Successfully uninstalled tensorflow-2.8.2+zzzcolab20220527125636\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-probability 0.16.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\n",
            "kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.15.2 which is incompatible.\u001b[0m\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.2 tensorflow-estimator-1.15.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "!python weight_convert.py\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0MOtBANxOCN",
        "outputId": "d00c8748-c686-4dd3-f2af-ea6f4cd5e8f0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /content/gdrive/MyDrive/study/deep/styleGAN/StyleGAN_LatentEditor/dnnlib/tflib/tfutil.py:34: The name tf.Dimension is deprecated. Please use tf.compat.v1.Dimension instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gdrive/MyDrive/study/deep/styleGAN/StyleGAN_LatentEditor/dnnlib/tflib/tfutil.py:74: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gdrive/MyDrive/study/deep/styleGAN/StyleGAN_LatentEditor/dnnlib/tflib/tfutil.py:128: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gdrive/MyDrive/study/deep/styleGAN/StyleGAN_LatentEditor/dnnlib/tflib/tfutil.py:97: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gdrive/MyDrive/study/deep/styleGAN/StyleGAN_LatentEditor/dnnlib/tflib/tfutil.py:109: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gdrive/MyDrive/study/deep/styleGAN/StyleGAN_LatentEditor/dnnlib/tflib/tfutil.py:132: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gdrive/MyDrive/study/deep/styleGAN/StyleGAN_LatentEditor/dnnlib/tflib/network.py:142: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gdrive/MyDrive/study/deep/styleGAN/StyleGAN_LatentEditor/dnnlib/tflib/network.py:150: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gdrive/MyDrive/study/deep/styleGAN/StyleGAN_LatentEditor/dnnlib/tflib/tfutil.py:76: The name tf.VariableScope is deprecated. Please use tf.compat.v1.VariableScope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gdrive/MyDrive/study/deep/styleGAN/StyleGAN_LatentEditor/dnnlib/tflib/network.py:151: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gdrive/MyDrive/study/deep/styleGAN/StyleGAN_LatentEditor/dnnlib/tflib/network.py:154: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gdrive/MyDrive/study/deep/styleGAN/StyleGAN_LatentEditor/dnnlib/tflib/network.py:182: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gdrive/MyDrive/study/deep/styleGAN/StyleGAN_LatentEditor/dnnlib/tflib/tfutil.py:200: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From <string>:364: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "sd only g_synthesis.blocks.8x8.conv0_up.intermediate.kernel torch.Size([1, 1, 3, 3])\n",
            "sd only g_synthesis.blocks.16x16.conv0_up.intermediate.kernel torch.Size([1, 1, 3, 3])\n",
            "sd only g_synthesis.blocks.32x32.conv0_up.intermediate.kernel torch.Size([1, 1, 3, 3])\n",
            "sd only g_synthesis.blocks.64x64.conv0_up.intermediate.kernel torch.Size([1, 1, 3, 3])\n",
            "sd only g_synthesis.blocks.128x128.conv0_up.intermediate.kernel torch.Size([1, 1, 3, 3])\n",
            "sd only g_synthesis.blocks.256x256.conv0_up.intermediate.kernel torch.Size([1, 1, 3, 3])\n",
            "sd only g_synthesis.blocks.512x512.conv0_up.intermediate.kernel torch.Size([1, 1, 3, 3])\n",
            "sd only g_synthesis.blocks.1024x1024.conv0_up.intermediate.kernel torch.Size([1, 1, 3, 3])\n",
            "sd only 1024x1024.blur.kernel torch.Size([1, 1, 3, 3])\n",
            "sd only 1024x1024.conv1_down.downscale.blur.kernel torch.Size([1, 1, 2, 2])\n",
            "sd only 512x512.blur.kernel torch.Size([1, 1, 3, 3])\n",
            "sd only 512x512.conv1_down.downscale.blur.kernel torch.Size([1, 1, 2, 2])\n",
            "sd only 256x256.blur.kernel torch.Size([1, 1, 3, 3])\n",
            "sd only 256x256.conv1_down.downscale.blur.kernel torch.Size([1, 1, 2, 2])\n",
            "sd only 128x128.blur.kernel torch.Size([1, 1, 3, 3])\n",
            "sd only 128x128.conv1_down.downscale.blur.kernel torch.Size([1, 1, 2, 2])\n",
            "sd only 64x64.blur.kernel torch.Size([1, 1, 3, 3])\n",
            "sd only 64x64.conv1_down.downscale.blur.kernel torch.Size([1, 1, 2, 2])\n",
            "sd only 32x32.blur.kernel torch.Size([1, 1, 3, 3])\n",
            "sd only 32x32.conv1_down.downscale.blur.kernel torch.Size([1, 1, 2, 2])\n",
            "sd only 16x16.blur.kernel torch.Size([1, 1, 3, 3])\n",
            "sd only 16x16.conv1_down.downscale.blur.kernel torch.Size([1, 1, 2, 2])\n",
            "sd only 8x8.blur.kernel torch.Size([1, 1, 3, 3])\n",
            "sd only 8x8.conv1_down.downscale.blur.kernel torch.Size([1, 1, 2, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "!mkdir save_image\n",
        "!mkdir save_image/encode1\n",
        "\n"
      ],
      "metadata": {
        "id": "l7UNq_suxm0S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "981eadb0-7841-4497-a9db-f14d25624f5b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘save_image’: File exists\n",
            "mkdir: cannot create directory ‘save_image/encode1’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "copy and overwite this code on 'encode_image.py'\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "from stylegan_layers import  G_mapping,G_synthesis\n",
        "from read_image import image_reader\n",
        "import argparse\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from collections import OrderedDict\n",
        "import torch.nn.functional as F\n",
        "from torchvision.utils import save_image\n",
        "from perceptual_model import VGG16_for_Perceptual\n",
        "import torch.optim as optim\n",
        "\n",
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "dlatent1= torch.zeros((1,18,512),requires_grad=True,device=device)\n",
        "dlatent2 = torch.zeros((1,18,512),requires_grad=True,device=device)\n",
        "\n",
        "def main(dlatent, source_image, do_synthesis):\n",
        "     parser = argparse.ArgumentParser(description='Find latent representation of reference images using perceptual loss')\n",
        "     parser.add_argument('--batch_size', default=1, help='Batch size for generator and perceptual model', type=int)\n",
        "     parser.add_argument('--resolution',default=1024,type=int)\n",
        "     parser.add_argument('--src_im',default=source_image)\n",
        "     parser.add_argument('--src_dir',default=\"source_image/\")\n",
        "     parser.add_argument('--weight_file',default=\"weight_files/pytorch/karras2019stylegan-ffhq-1024x1024.pt\",type=str)\n",
        "     parser.add_argument('--iteration',default=1000,type=int)\n",
        "\n",
        "\n",
        "\n",
        "     args=parser.parse_args()\n",
        "\n",
        "     g_all = nn.Sequential(OrderedDict([\n",
        "    ('g_mapping', G_mapping()),\n",
        "    #('truncation', Truncation(avg_latent)),\n",
        "    ('g_synthesis', G_synthesis(resolution=args.resolution))    \n",
        "    ]))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "     g_all.load_state_dict(torch.load(args.weight_file, map_location=device))\n",
        "     g_all.eval()\n",
        "     g_all.to(device)\n",
        "\n",
        "\n",
        "     g_mapping,g_synthesis=g_all[0],g_all[1]\n",
        "     name=args.src_im.split(\".\")[0]\n",
        "     img=image_reader(args.src_dir+args.src_im) #(1,3,1024,1024) -1~1\n",
        "     img=img.to(device)\n",
        "\n",
        "     MSE_Loss=nn.MSELoss(reduction=\"mean\")\n",
        "\n",
        "     img_p=img.clone() #Perceptual loss 用画像\n",
        "     upsample2d=torch.nn.Upsample(scale_factor=256/args.resolution, mode='bilinear') #VGG入力のため(256,256)にリサイズ\n",
        "     img_p=upsample2d(img_p)\n",
        "\n",
        "     perceptual_net=VGG16_for_Perceptual(n_layers=[2,4,14,21]).to(device)\n",
        "     \n",
        "     optimizer=optim.Adam({dlatent},lr=0.01,betas=(0.9,0.999),eps=1e-8)\n",
        "\n",
        "     print(\"Start\")\n",
        "     loss_list=[]\n",
        "     \n",
        "     for i in range(args.iteration):\n",
        "          optimizer.zero_grad()\n",
        "          synth_img=g_synthesis(dlatent)\n",
        "          synth_img = (synth_img + 1.0) / 2.0\n",
        "          mse_loss,perceptual_loss=caluclate_loss(synth_img,img,perceptual_net,img_p,MSE_Loss,upsample2d)\n",
        "          loss=mse_loss+perceptual_loss\n",
        "          loss.backward()\n",
        "\n",
        "          optimizer.step()\n",
        "\n",
        "          loss_np=loss.detach().cpu().numpy()\n",
        "          loss_p=perceptual_loss.detach().cpu().numpy()\n",
        "          loss_m=mse_loss.detach().cpu().numpy()\n",
        "\n",
        "          loss_list.append(loss_np)\n",
        "          if i%10==0:\n",
        "               print(\"iter{}: loss -- {},  mse_loss --{},  percep_loss --{}\".format(i,loss_np,loss_m,loss_p))\n",
        "               save_image(synth_img.clamp(0,1),\"save_image/encode1/{}_{}.png\".format(i,source_image))\n",
        "               #np.save(\"loss_list.npy\",loss_list)\n",
        "               np.save(\"latent_W/{}.npy\".format(name),dlatent.detach().cpu().numpy())\n",
        "     \n",
        "\n",
        "     if do_synthesis:\n",
        "       for i in range(10):\n",
        "        interpolated_img =g_synthesis(dlatent1 * (i / 10) + dlatent2 * ((10 - i) / 10))\n",
        "        interpolated_img = (interpolated_img + 1.0) / 2.0\n",
        "        print(\"interpolated image {} was made\".format(i))\n",
        "        save_image(interpolated_img.clamp(0,1),\"save_image/encode1/interpolated_{}.png\".format(i))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        \n",
        "\n",
        "\n",
        "          \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "          \n",
        "\n",
        "\n",
        "\n",
        "def caluclate_loss(synth_img,img,perceptual_net,img_p,MSE_Loss,upsample2d):\n",
        "     #calculate MSE Loss\n",
        "     mse_loss=MSE_Loss(synth_img,img) # (lamda_mse/N)*||G(w)-I||^2\n",
        "\n",
        "     #calculate Perceptual Loss\n",
        "     real_0,real_1,real_2,real_3=perceptual_net(img_p)\n",
        "     synth_p=upsample2d(synth_img) #(1,3,256,256)\n",
        "     synth_0,synth_1,synth_2,synth_3=perceptual_net(synth_p)\n",
        "\n",
        "     perceptual_loss=0\n",
        "     perceptual_loss+=MSE_Loss(synth_0,real_0)\n",
        "     perceptual_loss+=MSE_Loss(synth_1,real_1)\n",
        "     perceptual_loss+=MSE_Loss(synth_2,real_2)\n",
        "     perceptual_loss+=MSE_Loss(synth_3,real_3)\n",
        "\n",
        "     return mse_loss,perceptual_loss\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "     \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "     \n",
        "\n",
        "    \n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main(dlatent1, \"josh.png\", False)\n",
        "    main(dlatent2, \"thanos.png\", True)\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "GsB-_3Zs7LPJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "!python encode_image.py  --iteration 1500\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Stz8ehASzvis",
        "outputId": "68eb8b2b-d237-4fdf-a6ba-96620d3d6ccf"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100% 528M/528M [00:03<00:00, 167MB/s]\n",
            "Start\n",
            "iter0: loss -- 10.125829696655273,  mse_loss --0.2494492530822754,  percep_loss --9.876380920410156\n",
            "iter10: loss -- 5.2371368408203125,  mse_loss --0.2161749303340912,  percep_loss --5.020961761474609\n",
            "iter20: loss -- 5.091344833374023,  mse_loss --0.17458996176719666,  percep_loss --4.916754722595215\n",
            "iter30: loss -- 5.035895824432373,  mse_loss --0.1628619283437729,  percep_loss --4.8730340003967285\n",
            "iter40: loss -- 5.020185470581055,  mse_loss --0.16089880466461182,  percep_loss --4.859286785125732\n",
            "iter50: loss -- 5.007312774658203,  mse_loss --0.15403565764427185,  percep_loss --4.853277206420898\n",
            "iter60: loss -- 4.957531929016113,  mse_loss --0.15423151850700378,  percep_loss --4.803300380706787\n",
            "iter70: loss -- 4.9542717933654785,  mse_loss --0.15170128643512726,  percep_loss --4.802570343017578\n",
            "iter80: loss -- 4.943068027496338,  mse_loss --0.15145447850227356,  percep_loss --4.791613578796387\n",
            "iter90: loss -- 4.9226765632629395,  mse_loss --0.15132682025432587,  percep_loss --4.771349906921387\n",
            "iter100: loss -- 4.909297466278076,  mse_loss --0.15038049221038818,  percep_loss --4.758916854858398\n",
            "iter110: loss -- 4.9010138511657715,  mse_loss --0.14857356250286102,  percep_loss --4.752440452575684\n",
            "iter120: loss -- 4.86364221572876,  mse_loss --0.14695972204208374,  percep_loss --4.716682434082031\n",
            "iter130: loss -- 4.848312854766846,  mse_loss --0.1464451253414154,  percep_loss --4.701867580413818\n",
            "iter140: loss -- 4.793249607086182,  mse_loss --0.14494331181049347,  percep_loss --4.648306369781494\n",
            "iter150: loss -- 4.77886438369751,  mse_loss --0.1429452747106552,  percep_loss --4.635919094085693\n",
            "iter160: loss -- 4.7449870109558105,  mse_loss --0.14094236493110657,  percep_loss --4.604044437408447\n",
            "iter170: loss -- 4.646425724029541,  mse_loss --0.1373904049396515,  percep_loss --4.509035110473633\n",
            "iter180: loss -- 4.590449810028076,  mse_loss --0.1357218325138092,  percep_loss --4.454728126525879\n",
            "iter190: loss -- 4.513476848602295,  mse_loss --0.13264229893684387,  percep_loss --4.380834579467773\n",
            "iter200: loss -- 4.440720558166504,  mse_loss --0.12844231724739075,  percep_loss --4.3122782707214355\n",
            "iter210: loss -- 4.316512584686279,  mse_loss --0.12504754960536957,  percep_loss --4.191464900970459\n",
            "iter220: loss -- 4.240109920501709,  mse_loss --0.12098447978496552,  percep_loss --4.1191253662109375\n",
            "iter230: loss -- 4.153349876403809,  mse_loss --0.11786951124668121,  percep_loss --4.035480499267578\n",
            "iter240: loss -- 4.134440898895264,  mse_loss --0.11170583963394165,  percep_loss --4.022735118865967\n",
            "iter250: loss -- 4.572124481201172,  mse_loss --0.11479984223842621,  percep_loss --4.457324504852295\n",
            "iter260: loss -- 4.466426372528076,  mse_loss --0.12035755813121796,  percep_loss --4.346068859100342\n",
            "iter270: loss -- 4.3357625007629395,  mse_loss --0.11565738171339035,  percep_loss --4.220105171203613\n",
            "iter280: loss -- 4.189511775970459,  mse_loss --0.10747917741537094,  percep_loss --4.082032680511475\n",
            "iter290: loss -- 4.006464958190918,  mse_loss --0.09857569634914398,  percep_loss --3.9078891277313232\n",
            "iter300: loss -- 3.98154354095459,  mse_loss --0.09505598247051239,  percep_loss --3.8864874839782715\n",
            "iter310: loss -- 3.7525784969329834,  mse_loss --0.08802078664302826,  percep_loss --3.664557695388794\n",
            "iter320: loss -- 3.5683679580688477,  mse_loss --0.08133101463317871,  percep_loss --3.487036943435669\n",
            "iter330: loss -- 3.4794371128082275,  mse_loss --0.07249703258275986,  percep_loss --3.40693998336792\n",
            "iter340: loss -- 3.447971820831299,  mse_loss --0.06964359432458878,  percep_loss --3.378328323364258\n",
            "iter350: loss -- 3.3952279090881348,  mse_loss --0.06809154152870178,  percep_loss --3.327136278152466\n",
            "iter360: loss -- 3.4006967544555664,  mse_loss --0.06581255048513412,  percep_loss --3.3348841667175293\n",
            "iter370: loss -- 3.250575304031372,  mse_loss --0.06470726430416107,  percep_loss --3.18586802482605\n",
            "iter380: loss -- 3.2048773765563965,  mse_loss --0.061967842280864716,  percep_loss --3.142909526824951\n",
            "iter390: loss -- 3.2660915851593018,  mse_loss --0.06119208782911301,  percep_loss --3.204899549484253\n",
            "iter400: loss -- 3.053757905960083,  mse_loss --0.05892830714583397,  percep_loss --2.9948296546936035\n",
            "iter410: loss -- 3.111726999282837,  mse_loss --0.060008853673934937,  percep_loss --3.051718235015869\n",
            "iter420: loss -- 3.0304505825042725,  mse_loss --0.058331649750471115,  percep_loss --2.972118854522705\n",
            "iter430: loss -- 2.9817023277282715,  mse_loss --0.055230818688869476,  percep_loss --2.926471471786499\n",
            "iter440: loss -- 2.9286081790924072,  mse_loss --0.05271225422620773,  percep_loss --2.8758959770202637\n",
            "iter450: loss -- 2.9295616149902344,  mse_loss --0.05253347381949425,  percep_loss --2.877028226852417\n",
            "iter460: loss -- 2.9094655513763428,  mse_loss --0.05346982926130295,  percep_loss --2.8559956550598145\n",
            "iter470: loss -- 2.8098058700561523,  mse_loss --0.0512731671333313,  percep_loss --2.758532762527466\n",
            "iter480: loss -- 2.7516651153564453,  mse_loss --0.049902014434337616,  percep_loss --2.701763153076172\n",
            "iter490: loss -- 2.7034127712249756,  mse_loss --0.04879697784781456,  percep_loss --2.654615879058838\n",
            "iter500: loss -- 2.748448610305786,  mse_loss --0.04839058965444565,  percep_loss --2.7000579833984375\n",
            "iter510: loss -- 2.7264108657836914,  mse_loss --0.047548018395900726,  percep_loss --2.6788628101348877\n",
            "iter520: loss -- 2.679962158203125,  mse_loss --0.04738892614841461,  percep_loss --2.632573127746582\n",
            "iter530: loss -- 2.658783197402954,  mse_loss --0.04626917093992233,  percep_loss --2.612514019012451\n",
            "iter540: loss -- 2.6510961055755615,  mse_loss --0.04472538083791733,  percep_loss --2.606370687484741\n",
            "iter550: loss -- 2.599658250808716,  mse_loss --0.043782055377960205,  percep_loss --2.5558762550354004\n",
            "iter560: loss -- 2.506340742111206,  mse_loss --0.04436440393328667,  percep_loss --2.4619762897491455\n",
            "iter570: loss -- 2.5620830059051514,  mse_loss --0.042375460267066956,  percep_loss --2.519707441329956\n",
            "iter580: loss -- 2.5263590812683105,  mse_loss --0.04153983294963837,  percep_loss --2.484819173812866\n",
            "iter590: loss -- 2.5392823219299316,  mse_loss --0.04244038090109825,  percep_loss --2.4968419075012207\n",
            "iter600: loss -- 2.5442538261413574,  mse_loss --0.04293816536664963,  percep_loss --2.5013155937194824\n",
            "iter610: loss -- 2.474172353744507,  mse_loss --0.04090902954339981,  percep_loss --2.4332633018493652\n",
            "iter620: loss -- 2.5596773624420166,  mse_loss --0.041385333985090256,  percep_loss --2.51829195022583\n",
            "iter630: loss -- 2.4591875076293945,  mse_loss --0.0389227531850338,  percep_loss --2.420264720916748\n",
            "iter640: loss -- 2.361049175262451,  mse_loss --0.03966441750526428,  percep_loss --2.3213846683502197\n",
            "iter650: loss -- 2.3637490272521973,  mse_loss --0.03889515995979309,  percep_loss --2.3248538970947266\n",
            "iter660: loss -- 2.3797824382781982,  mse_loss --0.03776772692799568,  percep_loss --2.342014789581299\n",
            "iter670: loss -- 2.486346960067749,  mse_loss --0.03956156224012375,  percep_loss --2.4467854499816895\n",
            "iter680: loss -- 2.308494806289673,  mse_loss --0.03669452667236328,  percep_loss --2.2718002796173096\n",
            "iter690: loss -- 2.332233190536499,  mse_loss --0.03703196346759796,  percep_loss --2.295201301574707\n",
            "iter700: loss -- 2.3486921787261963,  mse_loss --0.036375146359205246,  percep_loss --2.312317132949829\n",
            "iter710: loss -- 2.2955617904663086,  mse_loss --0.03677888959646225,  percep_loss --2.2587828636169434\n",
            "iter720: loss -- 2.308912754058838,  mse_loss --0.03564746677875519,  percep_loss --2.2732653617858887\n",
            "iter730: loss -- 2.217487335205078,  mse_loss --0.034753695130348206,  percep_loss --2.1827335357666016\n",
            "iter740: loss -- 2.239614725112915,  mse_loss --0.035739656537771225,  percep_loss --2.2038750648498535\n",
            "iter750: loss -- 2.3342907428741455,  mse_loss --0.03518432006239891,  percep_loss --2.2991063594818115\n",
            "iter760: loss -- 2.2660608291625977,  mse_loss --0.03643263876438141,  percep_loss --2.229628086090088\n",
            "iter770: loss -- 2.2966506481170654,  mse_loss --0.035215914249420166,  percep_loss --2.26143479347229\n",
            "iter780: loss -- 2.2491796016693115,  mse_loss --0.034616269171237946,  percep_loss --2.2145633697509766\n",
            "iter790: loss -- 2.2359039783477783,  mse_loss --0.034317806363105774,  percep_loss --2.2015862464904785\n",
            "iter800: loss -- 2.1940219402313232,  mse_loss --0.03334803134202957,  percep_loss --2.1606738567352295\n",
            "iter810: loss -- 2.168571949005127,  mse_loss --0.033162541687488556,  percep_loss --2.135409355163574\n",
            "iter820: loss -- 2.1570305824279785,  mse_loss --0.033119089901447296,  percep_loss --2.1239113807678223\n",
            "iter830: loss -- 2.168602228164673,  mse_loss --0.0329430028796196,  percep_loss --2.1356592178344727\n",
            "iter840: loss -- 2.121884346008301,  mse_loss --0.03215701878070831,  percep_loss --2.0897274017333984\n",
            "iter850: loss -- 2.1866047382354736,  mse_loss --0.03264395892620087,  percep_loss --2.153960704803467\n",
            "iter860: loss -- 2.1778950691223145,  mse_loss --0.033109381794929504,  percep_loss --2.1447856426239014\n",
            "iter870: loss -- 2.0956380367279053,  mse_loss --0.03265472874045372,  percep_loss --2.062983274459839\n",
            "iter880: loss -- 2.154510736465454,  mse_loss --0.03172314539551735,  percep_loss --2.1227874755859375\n",
            "iter890: loss -- 2.1074299812316895,  mse_loss --0.030989404767751694,  percep_loss --2.0764405727386475\n",
            "iter900: loss -- 2.1473441123962402,  mse_loss --0.031226566061377525,  percep_loss --2.116117477416992\n",
            "iter910: loss -- 2.1527278423309326,  mse_loss --0.031442247331142426,  percep_loss --2.1212856769561768\n",
            "iter920: loss -- 2.091291904449463,  mse_loss --0.03021390363574028,  percep_loss --2.0610780715942383\n",
            "iter930: loss -- 2.190192222595215,  mse_loss --0.030738521367311478,  percep_loss --2.1594536304473877\n",
            "iter940: loss -- 2.106804609298706,  mse_loss --0.030954187735915184,  percep_loss --2.075850486755371\n",
            "iter950: loss -- 2.120319128036499,  mse_loss --0.030312329530715942,  percep_loss --2.0900068283081055\n",
            "iter960: loss -- 2.1017050743103027,  mse_loss --0.02982283942401409,  percep_loss --2.0718822479248047\n",
            "iter970: loss -- 2.098262310028076,  mse_loss --0.029906978830695152,  percep_loss --2.0683553218841553\n",
            "iter980: loss -- 2.195199728012085,  mse_loss --0.030509181320667267,  percep_loss --2.1646904945373535\n",
            "iter990: loss -- 2.0861382484436035,  mse_loss --0.030727416276931763,  percep_loss --2.055410861968994\n",
            "iter1000: loss -- 2.0123305320739746,  mse_loss --0.028857901692390442,  percep_loss --1.9834727048873901\n",
            "iter1010: loss -- 2.05465030670166,  mse_loss --0.028339620679616928,  percep_loss --2.026310682296753\n",
            "iter1020: loss -- 2.0031161308288574,  mse_loss --0.028553873300552368,  percep_loss --1.9745622873306274\n",
            "iter1030: loss -- 1.9998409748077393,  mse_loss --0.02789919078350067,  percep_loss --1.9719418287277222\n",
            "iter1040: loss -- 2.0774569511413574,  mse_loss --0.028944477438926697,  percep_loss --2.0485124588012695\n",
            "iter1050: loss -- 1.9945980310440063,  mse_loss --0.028518682345747948,  percep_loss --1.9660793542861938\n",
            "iter1060: loss -- 2.0599608421325684,  mse_loss --0.02909371815621853,  percep_loss --2.030867099761963\n",
            "iter1070: loss -- 1.9597833156585693,  mse_loss --0.02716933935880661,  percep_loss --1.9326139688491821\n",
            "iter1080: loss -- 2.034919261932373,  mse_loss --0.02728988602757454,  percep_loss --2.00762939453125\n",
            "iter1090: loss -- 1.9545179605484009,  mse_loss --0.027334492653608322,  percep_loss --1.9271835088729858\n",
            "iter1100: loss -- 1.9437004327774048,  mse_loss --0.027553102001547813,  percep_loss --1.9161473512649536\n",
            "iter1110: loss -- 1.9427627325057983,  mse_loss --0.027265070006251335,  percep_loss --1.9154976606369019\n",
            "iter1120: loss -- 1.9242745637893677,  mse_loss --0.026481932029128075,  percep_loss --1.8977925777435303\n",
            "iter1130: loss -- 1.8659981489181519,  mse_loss --0.02578860893845558,  percep_loss --1.8402094841003418\n",
            "iter1140: loss -- 1.9866371154785156,  mse_loss --0.025596152991056442,  percep_loss --1.96104097366333\n",
            "iter1150: loss -- 1.9449658393859863,  mse_loss --0.02711310237646103,  percep_loss --1.917852759361267\n",
            "iter1160: loss -- 2.0288758277893066,  mse_loss --0.02768033742904663,  percep_loss --2.0011954307556152\n",
            "iter1170: loss -- 1.9402683973312378,  mse_loss --0.026433292776346207,  percep_loss --1.913835048675537\n",
            "iter1180: loss -- 1.9201757907867432,  mse_loss --0.026470772922039032,  percep_loss --1.8937050104141235\n",
            "iter1190: loss -- 1.9367034435272217,  mse_loss --0.026178553700447083,  percep_loss --1.910524845123291\n",
            "iter1200: loss -- 1.9259421825408936,  mse_loss --0.025824805721640587,  percep_loss --1.9001173973083496\n",
            "iter1210: loss -- 1.9111429452896118,  mse_loss --0.02571164071559906,  percep_loss --1.8854312896728516\n",
            "iter1220: loss -- 1.884651780128479,  mse_loss --0.026642611250281334,  percep_loss --1.8580092191696167\n",
            "iter1230: loss -- 1.8968278169631958,  mse_loss --0.024738859385252,  percep_loss --1.87208890914917\n",
            "iter1240: loss -- 1.827174425125122,  mse_loss --0.02529480680823326,  percep_loss --1.801879644393921\n",
            "iter1250: loss -- 1.9528547525405884,  mse_loss --0.026242557913064957,  percep_loss --1.926612138748169\n",
            "iter1260: loss -- 1.872706651687622,  mse_loss --0.025810441002249718,  percep_loss --1.8468961715698242\n",
            "iter1270: loss -- 1.8385282754898071,  mse_loss --0.024959227070212364,  percep_loss --1.8135690689086914\n",
            "iter1280: loss -- 1.8426185846328735,  mse_loss --0.024207808077335358,  percep_loss --1.8184107542037964\n",
            "iter1290: loss -- 1.8626354932785034,  mse_loss --0.025275688618421555,  percep_loss --1.8373597860336304\n",
            "iter1300: loss -- 1.8021477460861206,  mse_loss --0.024127071723341942,  percep_loss --1.7780206203460693\n",
            "iter1310: loss -- 1.8987598419189453,  mse_loss --0.02558499202132225,  percep_loss --1.8731749057769775\n",
            "iter1320: loss -- 1.873728632926941,  mse_loss --0.025657113641500473,  percep_loss --1.848071575164795\n",
            "iter1330: loss -- 1.845973253250122,  mse_loss --0.02546071633696556,  percep_loss --1.8205125331878662\n",
            "iter1340: loss -- 1.847079873085022,  mse_loss --0.024525057524442673,  percep_loss --1.8225548267364502\n",
            "iter1350: loss -- 1.830644130706787,  mse_loss --0.023961659520864487,  percep_loss --1.8066824674606323\n",
            "iter1360: loss -- 1.7975890636444092,  mse_loss --0.024668511003255844,  percep_loss --1.7729206085205078\n",
            "iter1370: loss -- 1.823054552078247,  mse_loss --0.02500300109386444,  percep_loss --1.7980515956878662\n",
            "iter1380: loss -- 1.8027068376541138,  mse_loss --0.024397239089012146,  percep_loss --1.7783095836639404\n",
            "iter1390: loss -- 1.8089113235473633,  mse_loss --0.024365641176700592,  percep_loss --1.784545660018921\n",
            "iter1400: loss -- 1.7970534563064575,  mse_loss --0.024606671184301376,  percep_loss --1.7724467515945435\n",
            "iter1410: loss -- 1.8525216579437256,  mse_loss --0.023329194635152817,  percep_loss --1.8291925191879272\n",
            "iter1420: loss -- 1.8117815256118774,  mse_loss --0.02339823916554451,  percep_loss --1.7883832454681396\n",
            "iter1430: loss -- 1.8194652795791626,  mse_loss --0.023210793733596802,  percep_loss --1.7962545156478882\n",
            "iter1440: loss -- 1.749045491218567,  mse_loss --0.02311069145798683,  percep_loss --1.7259347438812256\n",
            "iter1450: loss -- 1.7688974142074585,  mse_loss --0.023573335260152817,  percep_loss --1.7453241348266602\n",
            "iter1460: loss -- 1.744179368019104,  mse_loss --0.02319377288222313,  percep_loss --1.7209856510162354\n",
            "iter1470: loss -- 1.8163414001464844,  mse_loss --0.023181378841400146,  percep_loss --1.7931599617004395\n",
            "iter1480: loss -- 1.7324389219284058,  mse_loss --0.022696634754538536,  percep_loss --1.7097423076629639\n",
            "iter1490: loss -- 1.767685890197754,  mse_loss --0.022915024310350418,  percep_loss --1.744770884513855\n",
            "Start\n",
            "iter0: loss -- 9.981359481811523,  mse_loss --0.2502477467060089,  percep_loss --9.731111526489258\n",
            "iter10: loss -- 5.075805187225342,  mse_loss --0.22492820024490356,  percep_loss --4.850876808166504\n",
            "iter20: loss -- 4.899939060211182,  mse_loss --0.14084786176681519,  percep_loss --4.759091377258301\n",
            "iter30: loss -- 4.800895690917969,  mse_loss --0.09501775354146957,  percep_loss --4.705877780914307\n",
            "iter40: loss -- 4.732531547546387,  mse_loss --0.08547966182231903,  percep_loss --4.647051811218262\n",
            "iter50: loss -- 4.66810417175293,  mse_loss --0.08370056003332138,  percep_loss --4.5844035148620605\n",
            "iter60: loss -- 4.61436653137207,  mse_loss --0.08216387778520584,  percep_loss --4.53220272064209\n",
            "iter70: loss -- 4.555428981781006,  mse_loss --0.07998597621917725,  percep_loss --4.475442886352539\n",
            "iter80: loss -- 4.490118503570557,  mse_loss --0.07756798714399338,  percep_loss --4.412550449371338\n",
            "iter90: loss -- 4.459769248962402,  mse_loss --0.07347892224788666,  percep_loss --4.386290550231934\n",
            "iter100: loss -- 4.362019062042236,  mse_loss --0.07157968729734421,  percep_loss --4.290439605712891\n",
            "iter110: loss -- 4.3012518882751465,  mse_loss --0.06829032301902771,  percep_loss --4.232961654663086\n",
            "iter120: loss -- 4.274477958679199,  mse_loss --0.06482025980949402,  percep_loss --4.209657669067383\n",
            "iter130: loss -- 4.309668064117432,  mse_loss --0.06263406574726105,  percep_loss --4.247034072875977\n",
            "iter140: loss -- 4.170161724090576,  mse_loss --0.06020195409655571,  percep_loss --4.109959602355957\n",
            "iter150: loss -- 4.202526092529297,  mse_loss --0.05830129235982895,  percep_loss --4.144224643707275\n",
            "iter160: loss -- 4.125226020812988,  mse_loss --0.05556466430425644,  percep_loss --4.0696611404418945\n",
            "iter170: loss -- 4.120622158050537,  mse_loss --0.05461563915014267,  percep_loss --4.066006660461426\n",
            "iter180: loss -- 3.9908854961395264,  mse_loss --0.051866840571165085,  percep_loss --3.939018726348877\n",
            "iter190: loss -- 3.9560489654541016,  mse_loss --0.04885569214820862,  percep_loss --3.907193183898926\n",
            "iter200: loss -- 3.9826302528381348,  mse_loss --0.047641247510910034,  percep_loss --3.9349889755249023\n",
            "iter210: loss -- 3.8402931690216064,  mse_loss --0.04434792324900627,  percep_loss --3.795945167541504\n",
            "iter220: loss -- 3.727970600128174,  mse_loss --0.04521646723151207,  percep_loss --3.6827540397644043\n",
            "iter230: loss -- 3.8741273880004883,  mse_loss --0.045509085059165955,  percep_loss --3.828618288040161\n",
            "iter240: loss -- 3.7775464057922363,  mse_loss --0.044031575322151184,  percep_loss --3.7335147857666016\n",
            "iter250: loss -- 3.7478437423706055,  mse_loss --0.043626271188259125,  percep_loss --3.7042174339294434\n",
            "iter260: loss -- 3.58388352394104,  mse_loss --0.04263895004987717,  percep_loss --3.5412445068359375\n",
            "iter270: loss -- 3.484563112258911,  mse_loss --0.04082069173455238,  percep_loss --3.443742513656616\n",
            "iter280: loss -- 3.36836576461792,  mse_loss --0.04015646502375603,  percep_loss --3.328209400177002\n",
            "iter290: loss -- 3.2846927642822266,  mse_loss --0.03742451220750809,  percep_loss --3.2472681999206543\n",
            "iter300: loss -- 3.341338872909546,  mse_loss --0.03648345544934273,  percep_loss --3.3048553466796875\n",
            "iter310: loss -- 3.2214975357055664,  mse_loss --0.034663017839193344,  percep_loss --3.1868345737457275\n",
            "iter320: loss -- 3.151197910308838,  mse_loss --0.035319648683071136,  percep_loss --3.1158783435821533\n",
            "iter330: loss -- 3.07100772857666,  mse_loss --0.03284727782011032,  percep_loss --3.038160562515259\n",
            "iter340: loss -- 3.048192024230957,  mse_loss --0.031022971495985985,  percep_loss --3.0171689987182617\n",
            "iter350: loss -- 2.977790117263794,  mse_loss --0.031218718737363815,  percep_loss --2.9465713500976562\n",
            "iter360: loss -- 2.961358070373535,  mse_loss --0.02948906645178795,  percep_loss --2.9318690299987793\n",
            "iter370: loss -- 2.926389455795288,  mse_loss --0.02909640222787857,  percep_loss --2.8972930908203125\n",
            "iter380: loss -- 2.924168348312378,  mse_loss --0.02880670689046383,  percep_loss --2.8953616619110107\n",
            "iter390: loss -- 2.929239511489868,  mse_loss --0.027743477374315262,  percep_loss --2.901495933532715\n",
            "iter400: loss -- 2.7920353412628174,  mse_loss --0.027569418773055077,  percep_loss --2.764465808868408\n",
            "iter410: loss -- 2.774773120880127,  mse_loss --0.0276446845382452,  percep_loss --2.747128486633301\n",
            "iter420: loss -- 2.708489418029785,  mse_loss --0.026225147768855095,  percep_loss --2.6822643280029297\n",
            "iter430: loss -- 2.7890496253967285,  mse_loss --0.026293938979506493,  percep_loss --2.7627556324005127\n",
            "iter440: loss -- 2.7333478927612305,  mse_loss --0.02639780007302761,  percep_loss --2.7069501876831055\n",
            "iter450: loss -- 2.7008488178253174,  mse_loss --0.02432647906243801,  percep_loss --2.6765222549438477\n",
            "iter460: loss -- 2.6752090454101562,  mse_loss --0.02422921173274517,  percep_loss --2.65097975730896\n",
            "iter470: loss -- 2.665825605392456,  mse_loss --0.02416083589196205,  percep_loss --2.641664743423462\n",
            "iter480: loss -- 2.587045431137085,  mse_loss --0.024250172078609467,  percep_loss --2.5627951622009277\n",
            "iter490: loss -- 2.595698833465576,  mse_loss --0.023165743798017502,  percep_loss --2.572533130645752\n",
            "iter500: loss -- 2.5639703273773193,  mse_loss --0.023292716592550278,  percep_loss --2.540677547454834\n",
            "iter510: loss -- 2.592994213104248,  mse_loss --0.022571001201868057,  percep_loss --2.570423126220703\n",
            "iter520: loss -- 2.550304651260376,  mse_loss --0.023632537573575974,  percep_loss --2.526672124862671\n",
            "iter530: loss -- 2.6069283485412598,  mse_loss --0.023646309971809387,  percep_loss --2.583281993865967\n",
            "iter540: loss -- 2.5228326320648193,  mse_loss --0.022849395871162415,  percep_loss --2.499983310699463\n",
            "iter550: loss -- 2.426213264465332,  mse_loss --0.022096216678619385,  percep_loss --2.4041171073913574\n",
            "iter560: loss -- 2.449786424636841,  mse_loss --0.023207947611808777,  percep_loss --2.4265785217285156\n",
            "iter570: loss -- 2.5152173042297363,  mse_loss --0.02166876569390297,  percep_loss --2.493548631668091\n",
            "iter580: loss -- 2.462226390838623,  mse_loss --0.021949362009763718,  percep_loss --2.440277099609375\n",
            "iter590: loss -- 2.417395830154419,  mse_loss --0.022240525111556053,  percep_loss --2.395155191421509\n",
            "iter600: loss -- 2.520951509475708,  mse_loss --0.02153892070055008,  percep_loss --2.4994125366210938\n",
            "iter610: loss -- 2.424617290496826,  mse_loss --0.021914493292570114,  percep_loss --2.402702808380127\n",
            "iter620: loss -- 2.416217088699341,  mse_loss --0.02153393253684044,  percep_loss --2.3946831226348877\n",
            "iter630: loss -- 2.388126850128174,  mse_loss --0.020992642268538475,  percep_loss --2.3671340942382812\n",
            "iter640: loss -- 2.441661834716797,  mse_loss --0.021198704838752747,  percep_loss --2.4204630851745605\n",
            "iter650: loss -- 2.3998970985412598,  mse_loss --0.021176880225539207,  percep_loss --2.378720283508301\n",
            "iter660: loss -- 2.3864052295684814,  mse_loss --0.02074282057583332,  percep_loss --2.3656623363494873\n",
            "iter670: loss -- 2.4387831687927246,  mse_loss --0.021270370110869408,  percep_loss --2.417512893676758\n",
            "iter680: loss -- 2.3596763610839844,  mse_loss --0.0207953080534935,  percep_loss --2.338881015777588\n",
            "iter690: loss -- 2.473515033721924,  mse_loss --0.02030899189412594,  percep_loss --2.4532060623168945\n",
            "iter700: loss -- 2.326376438140869,  mse_loss --0.019854998216032982,  percep_loss --2.306521415710449\n",
            "iter710: loss -- 2.3461854457855225,  mse_loss --0.020024478435516357,  percep_loss --2.3261609077453613\n",
            "iter720: loss -- 2.253058433532715,  mse_loss --0.019845977425575256,  percep_loss --2.233212471008301\n",
            "iter730: loss -- 2.3110532760620117,  mse_loss --0.019678544253110886,  percep_loss --2.291374683380127\n",
            "iter740: loss -- 2.2710418701171875,  mse_loss --0.019333679229021072,  percep_loss --2.2517082691192627\n",
            "iter750: loss -- 2.3719353675842285,  mse_loss --0.019735487177968025,  percep_loss --2.3521997928619385\n",
            "iter760: loss -- 2.313284158706665,  mse_loss --0.018977241590619087,  percep_loss --2.294306993484497\n",
            "iter770: loss -- 2.22542142868042,  mse_loss --0.019097138196229935,  percep_loss --2.206324338912964\n",
            "iter780: loss -- 2.3344128131866455,  mse_loss --0.019564522430300713,  percep_loss --2.3148481845855713\n",
            "iter790: loss -- 2.327486276626587,  mse_loss --0.019357217475771904,  percep_loss --2.308129072189331\n",
            "iter800: loss -- 2.3610427379608154,  mse_loss --0.018687654286623,  percep_loss --2.3423550128936768\n",
            "iter810: loss -- 2.250251054763794,  mse_loss --0.019232455641031265,  percep_loss --2.231018543243408\n",
            "iter820: loss -- 2.1903324127197266,  mse_loss --0.018112778663635254,  percep_loss --2.172219753265381\n",
            "iter830: loss -- 2.246495485305786,  mse_loss --0.01826535537838936,  percep_loss --2.2282302379608154\n",
            "iter840: loss -- 2.204336643218994,  mse_loss --0.017894357442855835,  percep_loss --2.1864423751831055\n",
            "iter850: loss -- 2.219174861907959,  mse_loss --0.01826474443078041,  percep_loss --2.2009100914001465\n",
            "iter860: loss -- 2.3151602745056152,  mse_loss --0.018679125234484673,  percep_loss --2.296481132507324\n",
            "iter870: loss -- 2.199897289276123,  mse_loss --0.018187422305345535,  percep_loss --2.1817097663879395\n",
            "iter880: loss -- 2.2044005393981934,  mse_loss --0.01808098331093788,  percep_loss --2.186319589614868\n",
            "iter890: loss -- 2.1877598762512207,  mse_loss --0.01771634630858898,  percep_loss --2.170043468475342\n",
            "iter900: loss -- 2.1680192947387695,  mse_loss --0.018075117841362953,  percep_loss --2.1499440670013428\n",
            "iter910: loss -- 2.2888848781585693,  mse_loss --0.018168944865465164,  percep_loss --2.2707159519195557\n",
            "iter920: loss -- 2.233029842376709,  mse_loss --0.018474910408258438,  percep_loss --2.214555025100708\n",
            "iter930: loss -- 2.192976713180542,  mse_loss --0.018103888258337975,  percep_loss --2.174872875213623\n",
            "iter940: loss -- 2.198992967605591,  mse_loss --0.017915088683366776,  percep_loss --2.1810779571533203\n",
            "iter950: loss -- 2.2329697608947754,  mse_loss --0.01811886951327324,  percep_loss --2.214850902557373\n",
            "iter960: loss -- 2.207883358001709,  mse_loss --0.018260307610034943,  percep_loss --2.1896231174468994\n",
            "iter970: loss -- 2.12933087348938,  mse_loss --0.01733989454805851,  percep_loss --2.1119909286499023\n",
            "iter980: loss -- 2.1491799354553223,  mse_loss --0.017259104177355766,  percep_loss --2.13192081451416\n",
            "iter990: loss -- 2.2116665840148926,  mse_loss --0.017284691333770752,  percep_loss --2.1943819522857666\n",
            "iter1000: loss -- 2.203028440475464,  mse_loss --0.018140193074941635,  percep_loss --2.1848883628845215\n",
            "iter1010: loss -- 2.1006298065185547,  mse_loss --0.017412247136235237,  percep_loss --2.0832176208496094\n",
            "iter1020: loss -- 2.2549118995666504,  mse_loss --0.017988774925470352,  percep_loss --2.2369232177734375\n",
            "iter1030: loss -- 2.2363109588623047,  mse_loss --0.017740312963724136,  percep_loss --2.2185707092285156\n",
            "iter1040: loss -- 2.1257784366607666,  mse_loss --0.016883624717593193,  percep_loss --2.1088948249816895\n",
            "iter1050: loss -- 2.2074339389801025,  mse_loss --0.01728988252580166,  percep_loss --2.1901440620422363\n",
            "iter1060: loss -- 2.1290552616119385,  mse_loss --0.017515821382403374,  percep_loss --2.111539363861084\n",
            "iter1070: loss -- 2.1359646320343018,  mse_loss --0.017201615497469902,  percep_loss --2.118762969970703\n",
            "iter1080: loss -- 2.158419370651245,  mse_loss --0.017543142661452293,  percep_loss --2.140876293182373\n",
            "iter1090: loss -- 2.1318349838256836,  mse_loss --0.016692202538251877,  percep_loss --2.115142822265625\n",
            "iter1100: loss -- 2.134432077407837,  mse_loss --0.01705818437039852,  percep_loss --2.1173739433288574\n",
            "iter1110: loss -- 2.0975594520568848,  mse_loss --0.016683928668498993,  percep_loss --2.0808756351470947\n",
            "iter1120: loss -- 2.0686042308807373,  mse_loss --0.016872651875019073,  percep_loss --2.051731586456299\n",
            "iter1130: loss -- 2.1393353939056396,  mse_loss --0.016251495108008385,  percep_loss --2.1230838298797607\n",
            "iter1140: loss -- 2.0549864768981934,  mse_loss --0.016880961135029793,  percep_loss --2.0381054878234863\n",
            "iter1150: loss -- 2.1290204524993896,  mse_loss --0.017078157514333725,  percep_loss --2.1119422912597656\n",
            "iter1160: loss -- 2.1005070209503174,  mse_loss --0.017084293067455292,  percep_loss --2.0834226608276367\n",
            "iter1170: loss -- 2.06853985786438,  mse_loss --0.016661789268255234,  percep_loss --2.051877975463867\n",
            "iter1180: loss -- 2.0989127159118652,  mse_loss --0.016963452100753784,  percep_loss --2.081949234008789\n",
            "iter1190: loss -- 2.0336380004882812,  mse_loss --0.01663358137011528,  percep_loss --2.0170044898986816\n",
            "iter1200: loss -- 2.0110464096069336,  mse_loss --0.0166998989880085,  percep_loss --1.9943466186523438\n",
            "iter1210: loss -- 2.0452890396118164,  mse_loss --0.016500024124979973,  percep_loss --2.0287890434265137\n",
            "iter1220: loss -- 2.0836613178253174,  mse_loss --0.015790201723575592,  percep_loss --2.06787109375\n",
            "iter1230: loss -- 2.019495964050293,  mse_loss --0.016754115000367165,  percep_loss --2.002741813659668\n",
            "iter1240: loss -- 2.039788007736206,  mse_loss --0.016107333824038506,  percep_loss --2.0236806869506836\n",
            "iter1250: loss -- 1.9977930784225464,  mse_loss --0.015812795609235764,  percep_loss --1.981980323791504\n",
            "iter1260: loss -- 2.098639726638794,  mse_loss --0.01612299121916294,  percep_loss --2.082516670227051\n",
            "iter1270: loss -- 2.008052349090576,  mse_loss --0.016091981902718544,  percep_loss --1.9919604063034058\n",
            "iter1280: loss -- 1.9479130506515503,  mse_loss --0.01596561074256897,  percep_loss --1.9319474697113037\n",
            "iter1290: loss -- 1.9904468059539795,  mse_loss --0.016005855053663254,  percep_loss --1.9744409322738647\n",
            "iter1300: loss -- 1.9896060228347778,  mse_loss --0.01610616222023964,  percep_loss --1.9734998941421509\n",
            "iter1310: loss -- 1.9770405292510986,  mse_loss --0.015464413911104202,  percep_loss --1.9615761041641235\n",
            "iter1320: loss -- 2.081881046295166,  mse_loss --0.015705035999417305,  percep_loss --2.066175937652588\n",
            "iter1330: loss -- 2.0183911323547363,  mse_loss --0.015972528606653214,  percep_loss --2.0024185180664062\n",
            "iter1340: loss -- 1.9892194271087646,  mse_loss --0.01571526564657688,  percep_loss --1.9735041856765747\n",
            "iter1350: loss -- 2.0136783123016357,  mse_loss --0.015968618914484978,  percep_loss --1.9977097511291504\n",
            "iter1360: loss -- 2.0282063484191895,  mse_loss --0.015700364485383034,  percep_loss --2.0125060081481934\n",
            "iter1370: loss -- 2.000861406326294,  mse_loss --0.01582290604710579,  percep_loss --1.98503839969635\n",
            "iter1380: loss -- 1.9870994091033936,  mse_loss --0.01546522043645382,  percep_loss --1.9716341495513916\n",
            "iter1390: loss -- 1.9912039041519165,  mse_loss --0.016192756593227386,  percep_loss --1.9750111103057861\n",
            "iter1400: loss -- 1.9893172979354858,  mse_loss --0.015994705259799957,  percep_loss --1.9733226299285889\n",
            "iter1410: loss -- 1.9969713687896729,  mse_loss --0.016043711453676224,  percep_loss --1.9809277057647705\n",
            "iter1420: loss -- 1.9780809879302979,  mse_loss --0.015465287491679192,  percep_loss --1.962615728378296\n",
            "iter1430: loss -- 2.0076427459716797,  mse_loss --0.016101336106657982,  percep_loss --1.9915415048599243\n",
            "iter1440: loss -- 1.9588645696640015,  mse_loss --0.015562711283564568,  percep_loss --1.9433019161224365\n",
            "iter1450: loss -- 1.9924826622009277,  mse_loss --0.015054195187985897,  percep_loss --1.9774284362792969\n",
            "iter1460: loss -- 1.920931339263916,  mse_loss --0.015052376314997673,  percep_loss --1.905879020690918\n",
            "iter1470: loss -- 2.1208975315093994,  mse_loss --0.015924235805869102,  percep_loss --2.104973316192627\n",
            "iter1480: loss -- 1.9866969585418701,  mse_loss --0.015511015430092812,  percep_loss --1.9711859226226807\n",
            "iter1490: loss -- 2.002948045730591,  mse_loss --0.015595488250255585,  percep_loss --1.9873524904251099\n",
            "interpolated image 0 was made\n",
            "interpolated image 1 was made\n",
            "interpolated image 2 was made\n",
            "interpolated image 3 was made\n",
            "interpolated image 4 was made\n",
            "interpolated image 5 was made\n",
            "interpolated image 6 was made\n",
            "interpolated image 7 was made\n",
            "interpolated image 8 was made\n",
            "interpolated image 9 was made\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python facial_exchange.py --src_im1  source_image/sample.png --src_im2  source_image/0.png  --iteration 200"
      ],
      "metadata": {
        "id": "SG1q1wv_3EJt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb4aabe5-437f-4636-e6be-c90043774277"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start\n",
            "iter0:   loss0 --3.2650365829467773,  loss1 --5.065891741651285e-07\n",
            "Traceback (most recent call last):\n",
            "  File \"facial_exchange.py\", line 193, in <module>\n",
            "    main()\n",
            "  File \"facial_exchange.py\", line 87, in main\n",
            "    loss_2.backward()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\", line 363, in backward\n",
            "    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\", line 175, in backward\n",
            "    allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "RuntimeError: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.FloatTensor [1, 512]], which is output 0 of AsStridedBackward0, is at version 2; expected version 1 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True).\n"
          ]
        }
      ]
    }
  ]
}